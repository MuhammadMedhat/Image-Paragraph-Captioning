{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DemoEncoder",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahomudgamalfcis/Image-Paragraph-Captioning/blob/master/DemoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgBSrgQhCNFH",
        "colab_type": "text"
      },
      "source": [
        "#1- Change Version of CUDA from 10.0 to 9.2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlaElJoKltGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check for Current version\n",
        "!nvcc --version\n",
        "#--------------------------------------------------\n",
        "\n",
        "# Uninstall the current version of CUDA\n",
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update\n",
        "#---------------------------------------------------\n",
        "\n",
        "# Install the new version of CUDA\n",
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9-2\n",
        "#---------------------------------------------------\n",
        "\n",
        "# check if CUDA 9.2 is installed\n",
        "!nvcc --version\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOLZMdF4DSsa",
        "colab_type": "text"
      },
      "source": [
        "#2- Setup Torch and It's Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ONhlFJ1l7ws1",
        "colab": {}
      },
      "source": [
        "# This Commands will install Torch with luaJIT\n",
        "!git clone https://github.com/nagadomi/distro.git ~/torch --recursive\n",
        "%cd ~/torch\n",
        "!bash install-deps\n",
        "!./update.sh\n",
        "!./install.sh\n",
        "#--------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyi0EfY8ZAgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this will install torch-rnn packcage\n",
        "!/root/torch/install/bin/luarocks  install https://raw.githubusercontent.com/jcjohnson/torch-rnn/master/torch-rnn-scm-1.rockspec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I-VeSJIZLDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' this command is to install stnbhw-scm-1, but it is a modified repo. we modified the CMakeLists file to change GPU architecture to \n",
        "fit the one which installed in Googel Colab. the line we changed is \n",
        " IF (CUDA_FOUND)\n",
        "   LIST(APPEND CUDA_NVCC_FLAGS \"-arch=sm_20\") To \n",
        "\n",
        " IF (CUDA_FOUND)\n",
        "   LIST(APPEND CUDA_NVCC_FLAGS \"-arch=sm_30\")'''\n",
        "!/root/torch/install/bin/luarocks install https://raw.githubusercontent.com/mahomudgamalfcis/stnbhwd/master/stnbhwd-scm-1.rockspec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6twl7vaRZPgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the commands below will install HDF5-1.10 \n",
        "%cd /content\n",
        "!git clone https://github.com/anibali/torch-hdf5.git\n",
        "%cd torch-hdf5\n",
        "!git checkout hdf5-1.10 \n",
        "!/root/torch/install/bin/luarocks make hdf5-0-0.rockspec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHsaSm4-Za21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this command to display Installed packages by Luarocks\n",
        "!/root/torch/install/bin/luarocks list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BknEZrgG-ly",
        "colab_type": "text"
      },
      "source": [
        "#3- Clone im2p repository "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6QiG0OCT_Wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/mahomudgamalfcis/im2p.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgbi3BJEJv3j",
        "colab_type": "text"
      },
      "source": [
        "### i- Download Training Images\n",
        "    the following cells is to make training images\n",
        "    ready for extracting features phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfq_P9firFvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import subprocess\n",
        "\n",
        "# Read paragraphs_va filea which contains all info about images\n",
        "allImageInformation = \"/content/im2p/data/paragraphs_v1.json\"\n",
        "with open(allImageInformation,'r') as all_imgs:\n",
        "    allImageData=json.load(all_imgs)\n",
        "print(len(allImageData))\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "# Read train_split file which contains all ids of training images\n",
        "train_imgs_ID = \"/content/im2p/data/train_split.json\"\n",
        "with open(train_imgs_ID,'r') as all_train_imgs:\n",
        "  trainImageID = json.load(all_train_imgs)\n",
        "print(len(trainImageID))\n",
        "#------------------------------------------\n",
        "\n",
        "# Download and install wget\n",
        "#!pip install wget\n",
        "#import wget\n",
        "#-----------------------------\n",
        "\n",
        "# Download all training images and save it in VG folder\n",
        "!mkdir -p /content/im2p/data/VG\n",
        "%cd /content/im2p/data/VG\n",
        "numberOfTrainingImages=0\n",
        "for ID in trainImageID:\n",
        "  for imgObj in allImageData:\n",
        "    if ID == imgObj['image_id']:\n",
        "      print(ID)\n",
        "      url_img = imgObj['url']\n",
        "      wget.download(url_img,'/content/im2p/data/VG')\n",
        "      train_images_path = \"/content/im2p/data/VG\"\n",
        "      train_images = glob.glob(train_images_path + \"/*.jpg\")\n",
        "      f = open(\"/content/im2p/data/VG/imgs_train_path.txt\", \"w\")\n",
        "      for item in train_images:\n",
        "          f.write(item + \"\\n\")\n",
        "      f.close()\n",
        "      \n",
        "      !cat /dev/null > /content/im2p/data/VG/imgs_train_path.txt\n",
        "      numberOfTrainingImages+=1\n",
        "      break\n",
        "  break\n",
        "print(numberOfTrainingImages)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HocfnFjJMx9b",
        "colab_type": "text"
      },
      "source": [
        "###v- Download pre-trained model of Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlP4sAsxb4ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data/models/densecap\n",
        "%cd ./data/models/densecap\n",
        "!wget http://cs.stanford.edu/people/jcjohns/densecap/densecap-pretrained-vgg16.t7.zip\n",
        "!unzip densecap-pretrained-vgg16.t7.zip\n",
        "!rm densecap-pretrained-vgg16.t7.zip\n",
        "%cd ../../../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHWY9xhMNYSi",
        "colab_type": "text"
      },
      "source": [
        "###vi- Extract feature for Training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF_jbqEYdBjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!/root/torch/install/bin/th /content/im2p/extract_features.lua -boxes_per_image 50 -max_images -1 -checkpoint /content/im2p/data/models/densecap/densecap-pretrained-vgg16.t7  -input_txt /content/im2p/imgs_train_path.txt \\\n",
        "                          -output_h5 ./data/im2p_train_output.h5 -gpu 0 -use_cudnn 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKuBDkOvN0WH",
        "colab_type": "text"
      },
      "source": [
        "###vii- Extract feature for Testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyVFAHdZODHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!/root/torch/install/bin/th /content/im2p/extract_features.lua -boxes_per_image 50 -max_images -1 -checkpoint /content/im2p/data/models/densecap/densecap-pretrained-vgg16.t7  -input_txt /content/im2p/imgs_test_path.txt \\\n",
        "                          -output_h5 ./data/im2p_test_output.h5 -gpu 0 -use_cudnn 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULaYABIUOGzT",
        "colab_type": "text"
      },
      "source": [
        "###viii- Extract feature for Validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9zVcJCTOVaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!/root/torch/install/bin/th /content/im2p/extract_features.lua -boxes_per_image 50 -max_images -1 -checkpoint /content/im2p/data/models/densecap/densecap-pretrained-vgg16.t7  -input_txt /content/im2p/imgs_val_path.txt \\\n",
        "                          -output_h5 ./data/im2p_val_output.h5 -gpu 0 -use_cudnn 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMzjIMooOqiV",
        "colab_type": "text"
      },
      "source": [
        "#4- Check the Output of Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6CgN11FfxMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "f = h5py.File(r'/content/im2p/data/im2p_train_output.h5')\n",
        "list(f)\n",
        "f['feats'].shape"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}