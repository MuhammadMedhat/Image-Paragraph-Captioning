{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DemoEncoder",
      "provenance": [],
      "authorship_tag": "ABX9TyN0My2lX64Sw/WXgP2Se5Ye",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahomudgamalfcis/Image-Paragraph-Captioning/blob/master/DemoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgBSrgQhCNFH",
        "colab_type": "text"
      },
      "source": [
        "#1- Change Version of CUDA from 10.0 to 9.2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlaElJoKltGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check for Current version\n",
        "!nvcc --version\n",
        "#--------------------------------------------------\n",
        "\n",
        "# Uninstall the current version of CUDA\n",
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update\n",
        "#---------------------------------------------------\n",
        "\n",
        "# Install the new version of CUDA\n",
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9-2\n",
        "#---------------------------------------------------\n",
        "\n",
        "# check if CUDA 9.2 is installed\n",
        "!nvcc --version\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOLZMdF4DSsa",
        "colab_type": "text"
      },
      "source": [
        "#2- Setup Torch and It's Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFXIOgEXmlYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Commands will install Torch with luaJIT\n",
        "!git clone https://github.com/nagadomi/distro.git ~/torch --recursive\n",
        "%cd ~/torch\n",
        "!bash install-deps\n",
        "!./update.sh\n",
        "!./install.sh\n",
        "#--------------------------------------------------\n",
        "\n",
        "# The commands below will install set of packages to make the model run successfully\n",
        "!/root/torch/install/bin/luarocks install torch\n",
        "!/root/torch/install/bin/luarocks install cutorch\n",
        "!/root/torch/install/bin/luarocks install cunn\n",
        "!/root/torch/install/bin/luarocks  install https://raw.githubusercontent.com/jcjohnson/torch-rnn/master/torch-rnn-scm-1.rockspec\n",
        "''' this command is to install stnbhw-scm-1, but it is a modified repo. we modified the CMakeLists file to change GPU architecture to \n",
        "fit the one which installed in Googel Colab. the line we changed is \n",
        " IF (CUDA_FOUND)\n",
        "   LIST(APPEND CUDA_NVCC_FLAGS \"-arch=sm_20\") To \n",
        "\n",
        " IF (CUDA_FOUND)\n",
        "   LIST(APPEND CUDA_NVCC_FLAGS \"-arch=sm_30\")'''\n",
        "!/root/torch/install/bin/luarocks install https://raw.githubusercontent.com/mahomudgamalfcis/stnbhwd/master/stnbhwd-scm-1.rockspec\n",
        "\n",
        "# the commands below will install HDF5-1.10 \n",
        "%cd /content\n",
        "!git clone https://github.com/anibali/torch-hdf5.git\n",
        "!cd torch-hdf5\n",
        "!git checkout hdf5-1.10 \n",
        "!/root/torch/install/bin/luarocks make hdf5-0-0.rockspec\n",
        "\n",
        "# this command to display Installed packages by Luarocks\n",
        "!/root/torch/install/bin/luarocks list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BknEZrgG-ly",
        "colab_type": "text"
      },
      "source": [
        "#3- Clone im2p repository "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6QiG0OCT_Wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/mahomudgamalfcis/im2p.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QdKxOu1T2ai",
        "colab_type": "text"
      },
      "source": [
        "###- Download Visual Genome \n",
        "      we have two files to download \n",
        "      1- genome_VG_100K_path (9 GB)\n",
        "      2- enome_VG_100K_path2 (5 GB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ong8Mw3MUQOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first download genome_VG_100K_path (9 GB)\n",
        "!mkdir -p /content/im2p/data/VG\n",
        "%cd /content/im2p/data/VG\n",
        "!wget https://cs.stanford.edu/people/rak248/VG_100K_2/images.zip\n",
        "!unzip images.zip\n",
        "!rm images.zip\n",
        "%cd ../../../\n",
        "#----------------------------------------------------------\n",
        "\n",
        "# second download genome_VG_100K_path2 (5 GB)\n",
        "!mkdir -p /content/im2p/data/VG2\n",
        "%cd /content/im2p/data/VG2\n",
        "!wget https://cs.stanford.edu/people/rak248/VG_100K_2/images2.zip\n",
        "!unzip images2.zip\n",
        "!rm images2.zip\n",
        "%cd ../../../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgbi3BJEJv3j",
        "colab_type": "text"
      },
      "source": [
        "### i- Run split_dataset.py file \n",
        "    this file is responsible for split our dataset to three parts\n",
        "      1- train dataset\n",
        "      2- test dataset\n",
        "      3- validation dataset\n",
        "    then it create a text file for each splitted dataset which contains all image paths to use it in extract feature step \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c25jlcI_UDnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python /content/im2p/split_dataset.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2uHoZz-K1-c",
        "colab_type": "text"
      },
      "source": [
        "###ii- Run get_imgs_train_path.py file\n",
        "    this file is responsible for getting all paths of images in training dataset and save it in another text file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e8M-d-JYEsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python /content/im2p/get_imgs_train_path.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzKacA9rLVaD",
        "colab_type": "text"
      },
      "source": [
        "###iii- Run get_imgs_test_path.py file\n",
        "  this file is responsible for getting all paths of images in testing dataset and save it in another text file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddOrWCOeLsPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python /content/im2p/get_imgs_test_path.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDd8WTQIL06b",
        "colab_type": "text"
      },
      "source": [
        "###iv- Run get_imgs_val_path.py file\n",
        "    this file is responsible for getting all paths of images in validation dataset and save it in another text file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMzGuNz8MM2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python /content/im2p/get_imgs_val_path.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HocfnFjJMx9b",
        "colab_type": "text"
      },
      "source": [
        "###v- Download pre-trained model of Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlP4sAsxb4ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data/models/densecap\n",
        "%cd ./data/models/densecap\n",
        "!wget http://cs.stanford.edu/people/jcjohns/densecap/densecap-pretrained-vgg16.t7.zip\n",
        "!unzip densecap-pretrained-vgg16.t7.zip\n",
        "!rm densecap-pretrained-vgg16.t7.zip\n",
        "%cd ../../../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHWY9xhMNYSi",
        "colab_type": "text"
      },
      "source": [
        "###vi- Extract feature for Training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF_jbqEYdBjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!/root/torch/install/bin/th /content/im2p/extract_features.lua -boxes_per_image 50 -max_images -1 -checkpoint /content/im2p/data/models/densecap/densecap-pretrained-vgg16.t7  -input_txt /content/im2p/imgs_train_path.txt \\\n",
        "                          -output_h5 ./data/im2p_train_output.h5 -gpu 0 -use_cudnn 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKuBDkOvN0WH",
        "colab_type": "text"
      },
      "source": [
        "###vii- Extract feature for Testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyVFAHdZODHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!/root/torch/install/bin/th /content/im2p/extract_features.lua -boxes_per_image 50 -max_images -1 -checkpoint /content/im2p/data/models/densecap/densecap-pretrained-vgg16.t7  -input_txt /content/im2p/imgs_test_path.txt \\\n",
        "                          -output_h5 ./data/im2p_test_output.h5 -gpu 0 -use_cudnn 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULaYABIUOGzT",
        "colab_type": "text"
      },
      "source": [
        "###viii- Extract feature for Validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9zVcJCTOVaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!/root/torch/install/bin/th /content/im2p/extract_features.lua -boxes_per_image 50 -max_images -1 -checkpoint /content/im2p/data/models/densecap/densecap-pretrained-vgg16.t7  -input_txt /content/im2p/imgs_val_path.txt \\\n",
        "                          -output_h5 ./data/im2p_val_output.h5 -gpu 0 -use_cudnn 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMzjIMooOqiV",
        "colab_type": "text"
      },
      "source": [
        "#4- Check the Output of Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6CgN11FfxMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "f = h5py.File(r'/content/im2p/data/im2p_train_output.h5')\n",
        "list(f)\n",
        "f['feats'].shape"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}